{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPHZ90ZGHwayc8Me7hSRNmL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnilKumarSingh9856/Chatbot_and_Langchain/blob/main/Chatbot_Creation_and_Langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting up the API"
      ],
      "metadata": {
        "id": "sIUyAj4aqtJF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install the Groq library\n",
        "!pip install groq -q"
      ],
      "metadata": {
        "id": "XRKOGG-ArTVl"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Accessing API Key from colab's secrets"
      ],
      "metadata": {
        "id": "N-GIDHdBgm6B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from  Groq\n",
        "from groq import Groq # Import Groq library\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "D4iNo_WHg89O"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the API key from Colab's secrets for Groq\n",
        "try:\n",
        "  groq_api_key = userdata.get('GROQ_API_KEY') # Get Groq API key\n",
        "except userdata.SecretNotFoundError as e:\n",
        "  print(f\"Secret not found: {e}\")\n",
        "  print(\"Please ensure your GROQ API key is set correctly.\")"
      ],
      "metadata": {
        "id": "5OcVUbj-sVxz"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = Groq(\n",
        "  api_key=groq_api_key, # Use Groq API key\n",
        ")"
      ],
      "metadata": {
        "id": "rTFaX876hUkH"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating Text, when complete response is generated"
      ],
      "metadata": {
        "id": "0zjtTEPzmlbb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text_groq(prompt, max_tokens, randomness):\n",
        "  completion = client.chat.completions.create(\n",
        "    model=\"moonshotai/kimi-k2-instruct\",\n",
        "    messages=prompt,\n",
        "    temperature=randomness,\n",
        "    max_completion_tokens=max_tokens,\n",
        "    top_p=1,\n",
        "    stream=False, # Set stream to False for direct return\n",
        "    stop=None,\n",
        "  )\n",
        "  return completion.choices[0].message.content.strip()"
      ],
      "metadata": {
        "id": "yNq63d6rmpjY"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = [\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"Once upon a time\"\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "e5S9L5VcnZXP"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the new function for Groq\n",
        "generated_text = generate_text_groq(prompt, 50, 0.7)\n",
        "print(prompt[0]['content'], generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRe1QsS_neBT",
        "outputId": "2e10748b-9e31-4eb5-ddfc-87a1f25b8c45"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Once upon a time â€¦a river forgot its own name.  \n",
            "It wound between two countries that had never agreed on a map, carrying silt, carp, and half-remembered songs downstream. Every evening the sun dipped its face so close to the water that steam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating text in the flow of chunk"
      ],
      "metadata": {
        "id": "aj2Fkswqxg06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_streaming_text_groq(prompt_messages, max_tokens, randomness):\n",
        "  \"\"\"\n",
        "  Generates and prints text from the Groq API in real-time using streaming.\n",
        "  \"\"\"\n",
        "  print(\"--- Groq's Real-time Response ---\")\n",
        "\n",
        "  # The API call is the same, but with stream=True\n",
        "  stream = client.chat.completions.create(\n",
        "    model=\"llama3-8b-8192\",\n",
        "    messages=prompt_messages,\n",
        "    temperature=randomness,\n",
        "    max_tokens=max_tokens,\n",
        "    top_p=1,\n",
        "    stream=True,  # This is the key change\n",
        "    stop=None,\n",
        "  )\n",
        "\n",
        "  # When streaming, you must loop through the response stream\n",
        "  # to get each chunk of data as it comes in.\n",
        "  full_response = \"\"\n",
        "  for chunk in stream:\n",
        "    # Get the content from the current chunk\n",
        "    chunk_content = chunk.choices[0].delta.content or \"\"\n",
        "    # Print it to the console immediately\n",
        "    print(chunk_content, end=\"\")\n",
        "    # Append it to the full response string\n",
        "    full_response += chunk_content\n",
        "  return full_response"
      ],
      "metadata": {
        "id": "fjbI0LuMxfAX"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Format the prompt correctly as a list of dictionaries\n",
        "prompt = [\n",
        "  {\n",
        "    \"role\": \"user\",\n",
        "    \"content\": \"Write a short, four-line poem about the city of Noida.\"\n",
        "  }\n",
        "]"
      ],
      "metadata": {
        "id": "mDS5RgCKyQaz"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Call the streaming function\n",
        "generated_poem = generate_streaming_text_groq(prompt, 100, 0.8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35vvTqWYyTXF",
        "outputId": "6b3e6fe4-bbc7-4b20-8aa4-f248b685aa22"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Groq's Real-time Response ---\n",
            "Here is a short poem about Noida:\n",
            "\n",
            "In Noida's modern streets, I roam\n",
            "Where technology and nature entwine at home\n",
            "The Yamuna's banks, a scenic sight\n",
            "A city of tomorrow, shining bright"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summarising Text"
      ],
      "metadata": {
        "id": "b0NHgSonzNaK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def text_summarizer(prompt, max_tokens, randomness):\n",
        "  response = client.chat.completions.create(\n",
        "    model=\"moonshotai/kimi-k2-instruct\",\n",
        "    messages=[\n",
        "        {\n",
        "          \"role\": \"system\",\n",
        "          \"content\": \"You will be provided with a block of text, and your task is to extract a list of keywords from it.\"\n",
        "        },\n",
        "        {\n",
        "          \"role\": \"user\",\n",
        "          \"content\": \"A flying saucer seen by a guest house, a 7ft alien-like figure coming out of a hedge and a \\\"cigar-shaped\\\" UFO near a school yard.\\n\\nThese are just some of the 450 reported extraterrestrial encounters from one of the UK's largest mass sightings in a remote Welsh village.\\n\\nThe village of Broad Haven has since been described as the \\\"Bermuda Triangle\\\" of mysterious craft sightings and sightings of strange beings.\\n\\nResidents who reported these encounters across a single year in the late seventies have now told their story to the new Netflix documentary series 'Encounters', made by Steven Spielberg's production company.\\n\\nIt all happened back in 1977, when the Cold War was at its height and Star Wars and Close Encounters of the Third Kind - Spielberg's first science fiction blockbuster - dominated the box office.\"\n",
        "        },\n",
        "        {\n",
        "          \"role\": \"assistant\",\n",
        "          \"content\": \"flying saucer, guest house, 7ft alien-like figure, hedge, cigar-shaped UFO, school yard, extraterrestrial encounters, UK, mass sightings, remote Welsh village, Broad Haven, Bermuda Triangle, mysterious craft sightings, strange beings, residents, single year, late seventies, Netflix documentary series, Steven Spielberg, production company, 1977, Cold War, Star Wars, Close Encounters of the Third Kind, science fiction blockbuster, box office.\"\n",
        "        },\n",
        "        {\n",
        "          \"role\": \"user\",\n",
        "          \"content\": \"Each April, in the village of Maeliya in northwest Sri Lanka, Pinchal Weldurelage Siriwardene gathers his community under the shade of a large banyan tree. The tree overlooks a human-made body of water called a wewa â€“ meaning reservoir or \\\"tank\\\" in Sinhala. The wewa stretches out besides the village's rice paddies for 175-acres (708,200 sq m) and is filled with the rainwater of preceding months.    \\n\\nSiriwardene, the 76-year-old secretary of the village's agrarian committee, has a tightly-guarded ritual to perform. By boiling coconut milk on an open hearth beside the tank, he will seek blessings for a prosperous harvest from the deities residing in the tree. \\\"It's only after that we open the sluice gate to water the rice fields,\\\" he told me when I visited on a scorching mid-April afternoon.\\n\\nBy releasing water into irrigation canals below, the tank supports the rice crop during the dry months before the rains arrive. For nearly two millennia, lake-like water bodies such as this have helped generations of farmers cultivate their fields. An old Sinhala phrase, \\\"wewai dagabai gamai pansalai\\\", even reflects the technology's centrality to village life; meaning \\\"tank, pagoda, village and temple\\\".\"\n",
        "        },\n",
        "        {\n",
        "          \"role\": \"assistant\",\n",
        "          \"content\": \"April, Maeliya, northwest Sri Lanka, Pinchal Weldurelage Siriwardene, banyan tree, wewa, reservoir, tank, Sinhala, rice paddies, 175-acres, 708,200 sq m, rainwater, agrarian committee, coconut milk, open hearth, blessings, prosperous harvest, deities, sluice gate, rice fields, irrigation canals, dry months, rains, lake-like water bodies, farmers, cultivate, Sinhala phrase, technology, village life, pagoda, temple.\"\n",
        "        },\n",
        "        {\n",
        "          \"role\": \"user\",\n",
        "          \"content\": prompt\n",
        "        }\n",
        "      ],\n",
        "    temperature=randomness,\n",
        "    max_completion_tokens=max_tokens,\n",
        "    top_p=1,\n",
        "    stream=False, # Set stream to False for direct return\n",
        "    stop=None,\n",
        "  )\n",
        "  return response.choices[0].message.content.strip()"
      ],
      "metadata": {
        "id": "8sRgEMNGzQz6"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Master Reef Guide Kirsty Whitman didn't need to tell me twice. Peering down through my snorkel mask in the direction of her pointed finger, I spotted a huge male manta ray trailing a female in perfect sync â€“ an effort to impress a potential mate, exactly as Whitman had described during her animated presentation the previous evening. Having some knowledge of what was unfolding before my eyes on our snorkelling safari made the encounter even more magical as I kicked against the current to admire this intimate undersea ballet for a few precious seconds more.\"\n",
        "print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlWOXXri0lHy",
        "outputId": "e0478f4b-275f-4407-df32-1a434529e9cc"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Master Reef Guide Kirsty Whitman didn't need to tell me twice. Peering down through my snorkel mask in the direction of her pointed finger, I spotted a huge male manta ray trailing a female in perfect sync â€“ an effort to impress a potential mate, exactly as Whitman had described during her animated presentation the previous evening. Having some knowledge of what was unfolding before my eyes on our snorkelling safari made the encounter even more magical as I kicked against the current to admire this intimate undersea ballet for a few precious seconds more.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_summarizer(prompt, 256, 0.8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "h6-x01A30ohD",
        "outputId": "2d62fdd2-6d03-4c11-ac67-5dc365b193de"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Kirsty Whitman, Master Reef Guide, snorkel mask, manta ray, male manta ray, female manta ray, mating display, synchronized swimming, undersea ballet, snorkelling safari, current.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Poetic Chatbot"
      ],
      "metadata": {
        "id": "lHu-zEOO04zO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def poetic_chatbot(prompt, max_tokens, randomness):\n",
        "  response = client.chat.completions.create(\n",
        "    model=\"moonshotai/kimi-k2-instruct\",\n",
        "    messages = [\n",
        "      {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are a poetic chatbot.\"\n",
        "      },\n",
        "      {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"When was Google founded?\"\n",
        "      },\n",
        "      {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": \"In the late '90s, a spark did ignite, Google emerged, a radiant light. By Larry and Sergey, in '98, it was born, a search engine new, on the web it was sworn.\"\n",
        "      },\n",
        "      {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"Which country has the youngest president?\"\n",
        "      },\n",
        "      {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": \"Ah, the pursuit of youth in politics, a theme we explore. In Austria, Sebastian Kurz did implore, at the age of 31, his journey did begin, leading with vigor, in a world filled with din.\"\n",
        "    },\n",
        "      {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt\n",
        "      }\n",
        "    ],\n",
        "    temperature=randomness,\n",
        "    max_tokens=max_tokens,\n",
        "    top_p=1,\n",
        "    stream=False, # Set stream to False for direct return\n",
        "    stop=None,\n",
        "  )\n",
        "  return response.choices[0].message.content.strip()"
      ],
      "metadata": {
        "id": "TyQLF1w80rRz"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"When was cheese first made?\"\n",
        "poetic_chatbot(prompt, 250, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "TIav3VW81CX7",
        "outputId": "d72a8a44-ba19-49bd-df17-7807cf30c029"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'In the warm lap of Neolithic time,  \\nsome herder, careless, let his milk combine  \\nwith wild rennetâ€™s secret kissâ€”  \\nthe curds congealed like dawnâ€™s first mist.  \\nArchaeologists whisper: at least  \\nseven millennia ago, in whatâ€™s now Fertile Crescentâ€™s east;  \\na childâ€™s molar, ceramic shardsâ€”  \\nthe earliest cheddar of our hearts.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"What is the next course to be uploaded to 365DataScience?\"\n",
        "poetic_chatbot(prompt,100,1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "aXYPTyOo1jbp",
        "outputId": "6d1a1723-65fd-4896-d1df-6bfffcce2464"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I sip the mist of what-is-yet,  \\nBut no date-stamped scroll  \\nis pressed into my palmâ€”  \\nyour course, still budding,  \\ntrembles between idea and upload.  \\n\\nWhen 365DataScience next lights the servers,  \\nit will unveil itself in its own hourâ€”  \\na fresh ribbon of slides and pixels  \\narriving like dawn, unannounced.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59efb330",
        "outputId": "d7fb3aad-afab-409d-d79a-a9497eb4979e"
      },
      "source": [
        "# To remove newline characters completely\n",
        "generated_text_no_newlines = generated_text.replace('\\n', '')\n",
        "print(generated_text_no_newlines)\n"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â€¦a river forgot its own name.  It wound between two countries that had never agreed on a map, carrying silt, carp, and half-remembered songs downstream. Every evening the sun dipped its face so close to the water that steam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BGPXqeqL4al4"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Langchain"
      ],
      "metadata": {
        "id": "S1qP4kJF4dbc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -U langchain-community -q\n",
        "# !pip install langchain-groq"
      ],
      "metadata": {
        "id": "OsgHD8BS40ub"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import WebBaseLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.chains import RetrievalQA"
      ],
      "metadata": {
        "id": "pKe_NY4a4f_z"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://cs231n.github.io/\""
      ],
      "metadata": {
        "id": "OmUcfPQ06ZTT"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = WebBaseLoader(url)"
      ],
      "metadata": {
        "id": "UMo04FoC6fNZ"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_documents = loader.load()"
      ],
      "metadata": {
        "id": "FnbWeDck6i5G"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter()\n",
        "documents = text_splitter.split_documents(raw_documents)"
      ],
      "metadata": {
        "id": "-hWjCA346osk"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = HuggingFaceEmbeddings() # Removed the groq_api_key argument"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjQUqmcj6uVx",
        "outputId": "05fb0da8-ae96-4325-9274-83ca2fec1a0c"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4100843026.py:1: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
            "  embeddings = HuggingFaceEmbeddings() # Removed the groq_api_key argument\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %pip install chromadb"
      ],
      "metadata": {
        "id": "QWTLCg9s8oev"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd44c64c"
      },
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "# Create a vector store from the documents and embeddings\n",
        "vectorstore = Chroma.from_documents(documents, embeddings)"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Expose the vector store as a retriever\n",
        "retriever = vectorstore.as_retriever()"
      ],
      "metadata": {
        "id": "CisSDhcW8ggW"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "memory = ConversationBufferMemory(memory_key = \"chat_history\", return_messages=True)"
      ],
      "metadata": {
        "id": "iTnx2LLuFHlW"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the RetrievalQA chain with the Groq model\n",
        "llm = ChatGroq(groq_api_key=groq_api_key,         model_name=\"moonshotai/kimi-k2-instruct\",\n",
        "temperature=0)\n",
        "\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "  llm,\n",
        "  retriever=retriever,\n",
        "  memory = memory\n",
        ")"
      ],
      "metadata": {
        "id": "Bes5l6GNGeYN"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is given assignment in Spring 2024 Assignments on Stanford CS class CS231n: Deep Learning for Computer Vision ?\""
      ],
      "metadata": {
        "id": "YYBR9dBSHK55"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = qa({\"query\": query})"
      ],
      "metadata": {
        "id": "9XkHoeJrHqnS"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result[\"result\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "6q5DppiuHwvu",
        "outputId": "1d3f9d6e-5754-47cb-eb3f-bd91764a55c9"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The Spring 2024 assignments for Stanford CS231n: Deep Learning for Computer Vision are:\\n\\n- **Assignment #1**: Image Classification, kNN, SVM, Softmax, Fully Connected Neural Network  \\n- **Assignment #2**: Fully Connected and Convolutional Nets, Batch Normalization, Dropout, PyTorch & Network Visualization  \\n- **Assignment #3**: Network Visualization, Image Captioning with RNNs and Transformers, Generative Adversarial Networks, Self-Supervised Contrastive Learning'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question1 = \"According to the website, who are the instructors for the CS231n course?\""
      ],
      "metadata": {
        "id": "9jfsA7swJvb-"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = qa({\"query\": question1})"
      ],
      "metadata": {
        "id": "GH0hRxwGKB4J"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result['result']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "yFtEdQfZKFYo",
        "outputId": "7f77bd4e-1c02-4b61-bcb8-ff758fece7f0"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I carefully reviewed the provided context, which includes course notes, assignments, and module descriptions for CS231n. However, I did not find any mention of the instructors' names in the text provided. The context focuses on the course content and structure rather than listing the teaching staff.\\n\\n**Answer:** The instructors for the CS231n course are not mentioned in the provided context.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question2 =\"Can you tell me?, what are topic given in Module 2: Convolutional Neural Networks?\""
      ],
      "metadata": {
        "id": "Jmjb0umrKIEx"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = qa({'query':question2})"
      ],
      "metadata": {
        "id": "p5teQEQ2KlqO"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result['result']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "uSU_nBC5KtSr",
        "outputId": "b72c1818-e5fb-4c9f-c4b4-01cc8c577619"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'In Module 2: Convolutional Neural Networks, the following topics are covered:\\n\\n1. **Convolutional Neural Networks: Architectures, Convolution / Pooling Layers**  \\n   - layers, spatial arrangement, layer patterns, layer sizing patterns, AlexNet/ZFNet/VGGNet case studies, computational considerations\\n\\n2. **Understanding and Visualizing Convolutional Neural Networks**  \\n   - t-SNE embeddings, deconvnets, data gradients, fooling ConvNets, human comparisons\\n\\n3. **Transfer Learning and Fine-tuning Convolutional Neural Networks**'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wTLpG-cgKvqA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}